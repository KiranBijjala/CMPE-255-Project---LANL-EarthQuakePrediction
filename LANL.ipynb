{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "from tsfresh.feature_extraction import extract_features, MinimalFCParameters\n",
    "%matplotlib inline\n",
    "\n",
    "WINDOW = 5000\n",
    "FILE = r'train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 481.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 646.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 714.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 469.27it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 751.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 732.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 716.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 498.49it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 838.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 741.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 654.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 542.04it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 526.33it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 487.14it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 729.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 528.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 1094.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 717.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 665.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00, 459.15it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "target = []\n",
    "mydata = pd.DataFrame()\n",
    "for chunk in pd.read_csv(FILE, chunksize=WINDOW,dtype={'acoustic_data': np.int8, 'time_to_failure': np.float32 },nrows=100000):\n",
    "    i += 1\n",
    "    chunk['id'] = i\n",
    "    extracted_features = extract_features(chunk.drop(columns=['time_to_failure']), column_id='id', n_jobs=4,default_fc_parameters=MinimalFCParameters())\n",
    "    mydata = pd.concat([mydata, extracted_features])\n",
    "    target.append(chunk.time_to_failure.iloc[-1])\n",
    "\n",
    "mydata['time_to_failure'] = target\n",
    "mydata.to_csv(r'ft_1m5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(r'ft_1m5.csv')\n",
    "dataframe = dataframe.dropna(axis=1)\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.drop(columns=['time_to_failure']), dataframe.time_to_failure, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation='relu'                   \n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    5.0s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.1151\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 49us/step - loss: 1.8030\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 86us/step - loss: 1.5457\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 52us/step - loss: 1.3265\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 51us/step - loss: 1.1385\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 50us/step - loss: 0.9793\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 67us/step - loss: 0.8419\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 57us/step - loss: 0.7251\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 42us/step - loss: 0.6258\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 46us/step - loss: 0.5413\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 48us/step - loss: 0.4699\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 82us/step - loss: 0.4089\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 65us/step - loss: 0.3568\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 73us/step - loss: 0.3126\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 44us/step - loss: 0.2748\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 47us/step - loss: 0.2426\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 57us/step - loss: 0.2156\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 71us/step - loss: 0.1927\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 46us/step - loss: 0.1733\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 87us/step - loss: 0.1570\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 63us/step - loss: 0.1432\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 53us/step - loss: 0.1316\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 46us/step - loss: 0.1218\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 48us/step - loss: 0.1135\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 50us/step - loss: 0.1065\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 49us/step - loss: 0.1006\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 52us/step - loss: 0.0955\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 63us/step - loss: 0.0912\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 50us/step - loss: 0.0874\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 48us/step - loss: 0.0841\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 47us/step - loss: 0.0812\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 58us/step - loss: 0.0787\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 53us/step - loss: 0.0764\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 46us/step - loss: 0.0743\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 46us/step - loss: 0.0725\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 43us/step - loss: 0.0707\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 47us/step - loss: 0.0692\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 57us/step - loss: 0.0677\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 51us/step - loss: 0.0663\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 62us/step - loss: 0.0651\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 65us/step - loss: 0.0639\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 60us/step - loss: 0.0627\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 48us/step - loss: 0.0616\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 45us/step - loss: 0.0605\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 55us/step - loss: 0.0595\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 55us/step - loss: 0.0585\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 47us/step - loss: 0.0576\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 57us/step - loss: 0.0566\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 43us/step - loss: 0.0557\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 45us/step - loss: 0.0548\n",
      "Best: -0.038088 using {'optimizer': 'SGD'}\n",
      "-0.038088 (0.020851) with: {'optimizer': 'SGD'}\n",
      "-0.226696 (0.173509) with: {'optimizer': 'RMSprop'}\n",
      "-0.081079 (0.043207) with: {'optimizer': 'Adagrad'}\n",
      "-0.124573 (0.030331) with: {'optimizer': 'Adadelta'}\n",
      "-0.320824 (0.225687) with: {'optimizer': 'Adam'}\n",
      "-0.094786 (0.080188) with: {'optimizer': 'Adamax'}\n",
      "-0.088741 (0.044011) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    1.454197\n",
      "5     1.461699\n",
      "19    1.443598\n",
      "6     1.460598\n",
      "15    1.448898\n",
      "9     1.456399\n",
      "2     1.465897\n",
      "1     1.466998\n",
      "16    1.447897\n",
      "12    1.453196\n",
      "17    1.446796\n",
      "10    1.455298\n",
      "0     1.468099\n",
      "13    1.451100\n",
      "Name: time_to_failure, dtype: float64\n",
      "[ 6 10  0  9  3  8 11 12  2  5  1  7 13  4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "print(y_train)\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "print(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  3 11 11  9  0]\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
